# =============================================================
# ğŸ‘¨â€ğŸ’» Ù…Ø·ÙˆØ± Ø§Ù„ÙƒÙˆØ¯: MTMA
# ğŸ“§ Ø§Ù„Ø¨Ø±ÙŠØ¯: mtma.1@hotmail.com
# ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹: iq.sa
#
# ØªØ§Ø±ÙŠØ® Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: 6 Ø£ØºØ³Ø·Ø³ 2025
# =============================================================

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
st.set_page_config(
    page_title="Ù…Ø®ØªØ¨Ø± MTMA", 
    layout="wide", 
    page_icon="ğŸ”¬", 
    initial_sidebar_state="expanded"
)

# Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø«Ø§Ø¨ØªØ©
x_train_data = np.array([
    [50, 1, 1, 1, 3.0, 15], [60, 1, 2, 2, 3.1, 12], [100, 3, 2, 4, 2.0, 5], [120, 3, 3, 5, 1.0, 2],
    [150, 4, 3, 4, 1.1, 3], [110, 2, 2, 3, 2.1, 8], [170, 4, 4, 5, 1.2, 1], [200, 5, 4, 5, 1.0, 0],
    [90, 2, 2, 2, 2.2, 18], [180, 4, 3, 4, 1.1, 5], [220, 5, 5, 5, 1.0, 1], [250, 6, 5, 5, 1.0, 0],
    [130, 3, 2, 3, 2.0, 7], [90, 2, 1, 2, 3.2, 20], [300, 6, 6, 5, 1.2, 2], [70, 1, 1, 2, 3.3, 25],
    [350, 7, 6, 5, 1.0, 1], [400, 7, 2, 5, 1.1, 4], [85, 2, 1, 3, 5.0, 10], [140, 3, 2, 4, 4.1, 6],
    [210, 4, 3, 4, 2.2, 3], [160, 4, 2, 3, 6.1, 14], [190, 5, 3, 5, 1.0, 0], [280, 5, 4, 4, 2.0, 5],
    [65, 2, 1, 2, 8.2, 22], [320, 6, 5, 5, 1.1, 2], [125, 3, 2, 4, 3.0, 3], [115, 3, 1, 3, 7.1, 16],
    [260, 5, 4, 5, 1.2, 1], [155, 4, 2, 4, 4.3, 4], [95, 2, 2, 3, 5.2, 9], [175, 4, 3, 4, 2.1, 7],
    [230, 5, 4, 5, 1.0, 2], [80, 2, 1, 2, 9.0, 28], [310, 6, 2, 5, 1.1, 3]
])
y_train_data = np.array([
    320000, 380000, 780000, 950000, 1150000, 750000, 1300000, 1550000, 550000, 1300000,
    1600000, 1800000, 880000, 480000, 2000000, 390000, 2300000, 2600000, 580000, 920000,
    1500000, 950000, 1450000, 1850000, 450000, 2100000, 960000, 610000, 1850000, 1100000,
    740000, 1320000, 1700000, 400000, 2200000
])
FEATURE_NAMES = ['Area', 'Rooms', 'Floors', 'Finishing', 'Neighborhood', 'Age', 'Area^2', 'Age^2', 'Finishing^2']
neighborhood_options = { "Al Olaya (Ø§Ù„Ø¹Ù„ÙŠØ§)": 1.0, "Al Malqa (Ø§Ù„Ù…Ù„Ù‚Ø§)": 1.1, "Ad Diriyah (Ø§Ù„Ø¯Ø±Ø¹ÙŠØ©)": 1.2, "Al Nakhil (Ø§Ù„Ù†Ø®ÙŠÙ„)": 2.0, "As Sahafah (Ø§Ù„ØµØ­Ø§ÙØ©)": 2.1, "Hittin (Ø­Ø·ÙŠÙ†)": 2.2, "Al Narjis (Ø§Ù„Ù†Ø±Ø¬Ø³)": 3.0, "Ar Rabi (Ø§Ù„Ø±Ø¨ÙŠØ¹)": 3.1, "Al Ghadir (Ø§Ù„ØºØ¯ÙŠØ±)": 3.2, "An Nada (Ø§Ù„Ù†Ø¯Ù‰)": 3.3, "Al Muruj (Ø§Ù„Ù…Ø±ÙˆØ¬)": 4.0, "Al Wadi (Ø§Ù„ÙˆØ§Ø¯ÙŠ)": 4.1, "Al Izdihar (Ø§Ù„Ø§Ø²Ø¯Ù‡Ø§Ø±)": 4.2, "As Sulimaniyah (Ø§Ù„Ø³Ù„ÙŠÙ…Ø§Ù†ÙŠØ©)": 4.3, "Thumamah (Ø§Ù„Ø«Ù…Ø§Ù…Ø©)": 4.4, "Al Yarmuk (Ø§Ù„ÙŠØ±Ù…ÙˆÙƒ)": 5.0, "Ar Rawdah (Ø§Ù„Ø±ÙˆØ¶Ø©)": 5.1, "Ar Rayyan (Ø§Ù„Ø±ÙŠØ§Ù†)": 5.2, "As Salam (Ø§Ù„Ø³Ù„Ø§Ù…)": 5.3, "Al Khaleej (Ø§Ù„Ø®Ù„ÙŠØ¬)": 5.4, "Al Fayha (Ø§Ù„ÙÙŠØ­Ø§Ø¡)": 6.0, "Al Faisaliyah (Ø§Ù„ÙÙŠØµÙ„ÙŠØ©)": 6.1, "Al Malaz (Ø§Ù„Ù…Ù„Ø²)": 6.2, "Ash Shifa (Ø§Ù„Ø´ÙØ§)": 6.3, "An Naseem (Ø§Ù„Ù†Ø³ÙŠÙ…)": 7.0, "Al Aziziyah (Ø§Ù„Ø¹Ø²ÙŠØ²ÙŠØ©)": 7.1, "Al Marwah (Ø§Ù„Ù…Ø±ÙˆØ©)": 7.2, "An Nadhim (Ø§Ù„Ù†Ø¸ÙŠÙ…)": 7.3, "As Suwaidi (Ø§Ù„Ø³ÙˆÙŠØ¯ÙŠ)": 8.0, "Dirab (Ø¯ÙŠØ±Ø§Ø¨)": 8.1, "Dhahrat Laban (Ø¸Ù‡Ø±Ø© Ù„Ø¨Ù†)": 8.2, "Namar (Ù†Ù…Ø§Ø±)": 8.3, "Al Urayja (Ø§Ù„Ø¹Ø±ÙŠØ¬Ø§Ø¡)": 9.0, "Badr (Ø¨Ø¯Ø±)": 9.1, "Irqah (Ø¹Ø±Ù‚Ø©)": 9.2, "Al Futah (Ø§Ù„ÙÙˆØ·Ø©)": 9.3, "Al Janadriyah (Ø§Ù„Ø¬Ù†Ø§Ø¯Ø±ÙŠØ©)": 10.0, "An Nadwah (Ø§Ù„Ù†Ø¯ÙˆØ©)": 10.1, "Al Batha (Ø§Ù„Ø¨Ø·Ø­Ø§Ø¡)": 10.2 }

# --- 2. Ù†Ø¸Ø§Ù… Ø§Ù„Ù„ØºØªÙŠÙ† ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø© ---
TEXTS = {
    'lang_choice': {'ar': "Ø§Ù„Ù„ØºØ©", 'en': "Language"},
    'page_choice': {'ar': "Ø§Ø®ØªØ± Ø§Ù„ØµÙØ­Ø©", 'en': "Select Page"},
    'page_lab': {'ar': "ğŸ”¬ Ø§Ù„Ù…Ø®ØªØ¨Ø± Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ", 'en': "ğŸ”¬ Interactive Lab"},
    'page_analysis': {'ar': "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡", 'en': "ğŸ“Š Performance Analysis"},
    'title': {'ar': "Ù…Ø®ØªØ¨Ø± MTMA Ù„ØªØ³Ø¹ÙŠØ± Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª", 'en': "MTMA's Real Estate Pricing Lab"},
    'intro': {'ar': "Ø£Ø¯Ø§Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ø¹Ø´Ø§Ù† ØªØ³ØªÙƒØ´Ù ÙƒÙŠÙ ÙŠØ£Ø«Ø± ØªØºÙŠÙŠØ± Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.", 'en': "An interactive tool to explore the impact of training parameters on an AI model's accuracy."},
    'training_settings_header': {'ar': "âš™ï¸ Ù…Ø¹Ø§ÙŠÙŠØ± ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø® Ø§Ù„Ø°ÙƒÙŠ", 'en': "âš™ï¸ Smart Brain Training Parameters"},
    'optimizer_label': {'ar': "ğŸš€ Ø§Ø®ØªØ± Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¯Ø±ÙŠØ¨", 'en': "ğŸš€ Choose Training Optimizer"},
    'optimizer_help': {'ar': "GD Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ù‡Ùˆ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ. Adam Ø§Ù„Ù…Ø·ÙˆØ± Ø£Ø°ÙƒÙ‰ ÙˆØ£Ø³Ø±Ø¹ ØºØ§Ù„Ø¨Ù‹Ø§.", 'en': "Standard GD is the basic one. Adam is often smarter and faster."},
    'poly_label': {'ar': "ğŸ§  ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Polynomial)", 'en': "ğŸ§  Enable Advanced View (Polynomial)"},
    'poly_help': {'ar': "ÙŠØ³Ù…Ø­ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙÙ‡Ù… Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¨ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙŠØ²ÙŠØ¯ Ø§Ù„Ø¯Ù‚Ø© Ù„ÙƒÙ† ÙŠØ¨Ø·Ø¦ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.", 'en': "Allows the model to understand complex data relationships, increasing accuracy but slowing down training."},
    'epochs_label': {'ar': "ğŸ”„ ÙƒÙ… Ù…Ø±Ø© ØªØ¨ØºÙ‰ Ø§Ù„Ù…Ø® ÙŠØªØ¯Ø±Ø¨ØŸ (Epochs)", 'en': "ğŸ”„ How many training cycles for the brain? (Epochs)"},
    'epochs_help': {'ar': "ÙŠÙ…Ø«Ù„ ÙƒÙ… Ù…Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ±Ø§Ø¬Ø¹ Ø§Ù„Ø¯Ø§ØªØ§ ÙƒØ§Ù…Ù„Ø©. ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯ØŒ ØªØ¹Ù„Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ«Ø± ÙˆØµØ§Ø± Ø£Ø¯Ù‚ (Ø¨Ø³ ÙŠØ§Ø®Ø° ÙˆÙ‚Øª Ø£Ø·ÙˆÙ„).", 'en': "The number of times the model reviews the entire dataset. A higher value means more learning and better accuracy (but takes longer)."},
    'alpha_label': {'ar': "âš¡ï¸ Ø³Ø±Ø¹Ø© ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø® (Alpha)", 'en': "âš¡ï¸ Brain's Learning Rate (Alpha)"},
    'alpha_help': {'ar': "ØªØªØ­ÙƒÙ… ÙÙŠ Ø­Ø¬Ù… Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØµØ­ÙŠØ­. Ø±Ù‚Ù… ØµØºÙŠØ± ÙŠØ¹Ù†ÙŠ ØªØ¹Ù„Ù… Ø¨Ø·ÙŠØ¡ ÙˆØ­Ø°Ø±ØŒ ÙˆØ±Ù‚Ù… ÙƒØ¨ÙŠØ± ÙŠØ¹Ù†ÙŠ ØªØ¹Ù„Ù… Ø³Ø±ÙŠØ¹ ÙˆÙ…Ù…ÙƒÙ† 'ÙŠØ´Ø·Ø­' ÙˆÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ù„ Ø§Ù„ØµØ­.", 'en': "Controls the size of corrective steps. A small value means slow, careful learning; a large value might 'overshoot' the correct solution."},
    'property_details_header': {'ar': "ğŸ¡ Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„Ø¹Ù‚Ø§Ø± Ø§Ù„Ù„ÙŠ ØªØ¨ÙŠ ØªØ³Ø¹Ù‘Ø±Ù‡", 'en': "ğŸ¡ Details of The Property to be Priced"},
    'area_label': {'ar': "ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø­Ø© (Ø¨Ø§Ù„Ù…ØªØ± Ø§Ù„Ù…Ø±Ø¨Ø¹)", 'en': "ğŸ“ Area (in square meters)"},
    'rooms_label': {'ar': "ğŸ›ï¸ Ø¹Ø¯Ø¯ Ø§Ù„ØºØ±Ù", 'en': "ğŸ›ï¸ Number of Rooms"},
    'floors_label': {'ar': "ğŸ¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø·ÙˆØ§Ø¨Ù‚", 'en': "ğŸ¢ Number of Floors"},
    'finishing_label': {'ar': "âœ¨ Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ´Ø·ÙŠØ¨", 'en': "âœ¨ Finishing Quality"},
    'age_label': {'ar': "â³ Ø¹Ù…Ø± Ø§Ù„Ø¹Ù‚Ø§Ø± (Ø¨Ø§Ù„Ø³Ù†ÙˆØ§Øª)", 'en': "â³ Property Age (in years)"},
    'neighborhood_label': {'ar': "ğŸ“ Ø§Ø®ØªØ± Ø§Ù„Ø­ÙŠ", 'en': "ğŸ“ Select Neighborhood"},
    'button_text': {'ar': "Ø­Ù„Ù‘Ù„ ÙˆØ³Ø¹Ù‘Ø±!", 'en': "Analyze & Price!"},
    'spinner_text': {'ar': "Ù„Ø­Ø¸Ø§Øª... Ø§Ù„Ù…Ø® Ø§Ù„Ø°ÙƒÙŠ ÙŠÙÙƒØ± ÙˆÙŠØªØ¯Ø±Ø¨", 'en': "Just a moment... the smart brain is thinking and training"},
    'results_header': {'ar': "ğŸ“Š Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„Ùƒ ÙˆØªØ®Ù…ÙŠÙ† Ø§Ù„Ø³Ø¹Ø±", 'en': "ğŸ“Š Your Analysis & Price Estimation"},
    'price_label': {'ar': "ğŸ’° Ø§Ù„Ø³Ø¹Ø± Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ÙŠ (SAR)", 'en': "ğŸ’° Estimated Price (SAR)"},
    'initial_cost_label': {'ar': "ğŸ“‰ Ø§Ù„Ø®Ø·Ø£ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Cost)", 'en': "ğŸ“‰ Initial Cost (Before Training)"},
    'final_cost_label': {'ar': "ğŸ“‰ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Cost)", 'en': "ğŸ“‰ Final Cost (After Training)"},
    'cost_help': {'ar': "Ù‡Ø°Ø§ Ø§Ù„Ø±Ù‚Ù… ÙŠÙ…Ø«Ù„ Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ù‡Ø¯ÙÙ†Ø§ Ù‡Ùˆ ØªÙ‚Ù„ÙŠÙ„Ù‡ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†.", 'en': "This number represents the Mean Squared Error of the model. Our goal is to minimize it as much as possible."},
    'rmse_label': {'ar': "ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ (RMSE)", 'en': "ğŸ¯ Average Error (RMSE)"},
    'rmse_help': {'ar': "ÙŠÙ…Ø«Ù„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·Ø£ Ø§Ù„ÙØ¹Ù„ÙŠ ÙÙŠ ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø¨Ø§Ù„Ø¢Ù Ø§Ù„Ø±ÙŠØ§Ù„Ø§Øª). Ø±Ù‚Ù… Ø£Ù‚Ù„ ÙŠØ¹Ù†ÙŠ Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰.", 'en': "Represents the average actual prediction error in the same unit as the price (K SAR). A lower number means higher accuracy."},
    'tip_header': {'ar': "ğŸ’¡ ÙˆØ´ ØªØ¹Ù†ÙŠ Ù‡Ø§Ù„Ø£Ø±Ù‚Ø§Ù…ØŸ | Ø¨Ù‚Ù„Ù… MTMA", 'en': "ğŸ’¡ What Do These Numbers Mean? | by MTMA"},
    'tip_text': {'ar': "**- Ø²ÙŠØ§Ø¯Ø© Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Epochs):** Ø¨ØªÙ„Ø§Ø­Ø¸ Ø¥Ù† Ø±Ù‚Ù… 'Ø§Ù„Ø®Ø·Ø£ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨' ÙŠØµØºØ±ØŒ ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø¥Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØµØ§Ø± Ø£Ø¯Ù‚. Ø¨Ø³ Ù„Ùˆ Ø²Ø¯ØªÙ‡ Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ù„Ø§Ø²Ù… Ù…Ù…ÙƒÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ÙØ¸ Ø§Ù„Ø¯Ø§ØªØ§ Ø­ÙØ¸ Ù…Ùˆ ÙÙ‡Ù….\n\n**- ØªØ¹Ø¯ÙŠÙ„ Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ¹Ù„Ù… (Alpha):** Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ø±Ù‚Ù… ØµØºÙŠØ± Ù…Ø±Ø©ØŒ Ø¨ÙŠÙƒÙˆÙ† Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø·ÙŠØ¡. Ù„Ùˆ ÙƒØ§Ù† ÙƒØ¨ÙŠØ± Ù…Ø±Ø©ØŒ Ø¨ØªÙ„Ø§Ø­Ø¸ Ø¥Ù† 'Ø§Ù„Ø®Ø·Ø£ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨' ÙŠØµÙŠØ± Ø±Ù‚Ù… ÙÙ„ÙƒÙŠØŒ ÙŠØ¹Ù†ÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 'Ø´Ø·Ø­' ÙˆÙ…Ø§ Ù‚Ø¯Ø± ÙŠØªØ¹Ù„Ù… ØµØ­.", 'en': "**- Increasing Epochs:** You'll notice the 'Final Cost' number gets smaller, which means the model is getting more accurate. But if you increase it too much, the model might just memorize the data, not learn from it.\n\n**- Adjusting Alpha:** If the rate is too small, learning will be slow. If it's too large, you'll notice the 'Final Cost' becomes a huge number, meaning the model 'overshoot' and failed to learn properly."},
    'divergence_error': {'ar': "ğŸš¨ **ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Divergence)!**\n\nÙ‚ÙŠÙ…Ø© 'Ø§Ù„Ø®Ø·Ø£ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨' ØµØ§Ø±Øª ÙÙ„ÙƒÙŠØ© ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† **Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ¹Ù„Ù… (Alpha) ÙƒØ§Ù†Øª Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ù‹Ø§** ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ 'Ø´Ø·Ø­'. Ø¬Ø±Ø¨ Ù‚ÙŠÙ…Ø© Ø£ØµØºØ±.", 'en': "ğŸš¨ **Training Failed (Divergence)!**\n\nThe 'Final Cost' became astronomical, which means the **Learning Rate (Alpha) was too high** and the model diverged. Try a smaller value."},
    'analysis_title': {'ar': "ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", 'en': "Model Performance Analysis"},
    'analysis_intro': {'ar': "Ù‡Ù†Ø§ Ù†Ø´ÙˆÙ ÙƒÙŠÙ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨. Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© ØªÙ‚Ø§Ø±Ù† Ø¨ÙŠÙ† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆØ§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù„ÙŠ ØªÙˆÙ‚Ø¹Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.", 'en': "Here we see how the model performs on the training data. The charts compare the actual prices with the prices predicted by the model."},
    'run_lab_first': {'ar': "Ù„Ø§Ø²Ù… Ø£ÙˆÙ„ Ø´ÙŠ ØªØ³ÙˆÙŠ ØªØ­Ù„ÙŠÙ„ ÙÙŠ ØµÙØ­Ø© 'Ø§Ù„Ù…Ø®ØªØ¨Ø± Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ' Ø¹Ø´Ø§Ù† ØªØ·Ù„Ø¹ Ù„Ùƒ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù‡Ù†Ø§.", 'en': "You must first run an analysis on the 'Interactive Lab' page to see the results here."},
    'summary_header': {'ar': "Ù…Ù„Ø®Øµ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©", 'en': "Summary of Parameters Used"},
    'summary_optimizer': {'ar': "Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ¯Ø±ÙŠØ¨", 'en': "Optimizer"},
    'summary_poly': {'ar': "Ø§Ù„Ù†Ø¸Ø±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©", 'en': "Advanced View"},
    'summary_epochs': {'ar': "Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨", 'en': "Epochs"},
    'summary_alpha': {'ar': "Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ¹Ù„Ù…", 'en': "Learning Rate"},
    'summary_final_cost': {'ar': "Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", 'en': "Final Cost"},
    'charts_header': {'ar': "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ (Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©)", 'en': "Visual Analysis (in English)"},
    'chart_actual_vs_pred_title': {'en': "Actual vs. Predicted Prices"},
    'chart_actual_vs_pred_xaxis': {'en': "Actual Price (in Thousands SAR)"},
    'chart_actual_vs_pred_yaxis': {'en': "Predicted Price (in Thousands SAR)"},
    'chart_residuals_title': {'en': "Residuals Plot (Errors)"},
    'chart_residuals_xaxis': {'en': "Predicted Price (in Thousands SAR)"},
    'chart_residuals_yaxis': {'en': "Residual (Actual - Predicted)"},
    'chart_importance_title': {'en': "Feature Importance (Model Weights)"},
    'chart_convergence_title': {'en': "Cost Convergence Curve"},
    'chart_convergence_xaxis': {'en': "Epochs"},
    'chart_convergence_yaxis': {'en': "Cost (MSE)"},
    'table_header': {'ar': "Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ (Ø¨Ø§Ù„Ø¢Ù„Ø§Ù)", 'en': "Detailed Results Table (in Thousands)"},
    'params_header': {'ar': "Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù„ÙŠ ØªØ¹Ù„Ù…Ù‡Ø§ Ø§Ù„Ù…Ø® Ø§Ù„Ø°ÙƒÙŠ", 'en': "Learned Model Parameters (Weights)"},
    'data_header': {'ar': "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù„ÙŠ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§Ù‡Ø§", 'en': "Training Data Used"}
}

# --- 3. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ---
@st.cache_data
def train_live_model(epochs, alpha, use_poly, optimizer):
    print(f"ğŸš€ Training: epochs={epochs}, alpha={alpha}, poly={use_poly}, optimizer={optimizer}")
    
    x_train = x_train_data.copy()
    feature_names = FEATURE_NAMES[:6]
    if use_poly:
        x_train = np.c_[x_train, x_train[:, 0]**2, x_train[:, 5]**2, x_train[:, 3]**2]
        feature_names = FEATURE_NAMES

    y_train_scaled = y_train_data / 1000.0

    x_mean = np.mean(x_train, axis=0)
    x_std = np.std(x_train, axis=0)
    x_std[x_std == 0] = 1 
    x_scaled = (x_train - x_mean) / x_std
    
    w = np.zeros(x_train.shape[1])
    b = 1e-6
    m = x_train.shape[0]

    v_dw, s_dw = np.zeros(w.shape), np.zeros(w.shape)
    v_db, s_db = 0, 0
    beta1, beta2, epsilon = 0.9, 0.999, 1e-8

    initial_cost = (1 / (2 * m)) * np.sum((np.dot(x_scaled, w) + b - y_train_scaled) ** 2)
    cost_history = []

    for i in range(epochs):
        error = np.dot(x_scaled, w) + b - y_train_scaled
        gradient_w = (1 / m) * np.dot(x_scaled.T, error)
        gradient_b = (1 / m) * np.sum(error)
        
        if optimizer == 'Adam':
            v_dw = beta1 * v_dw + (1 - beta1) * gradient_w
            v_db = beta1 * v_db + (1 - beta1) * gradient_b
            s_dw = beta2 * s_dw + (1 - beta2) * (gradient_w**2)
            s_db = beta2 * s_db + (1 - beta2) * (gradient_b**2)
            w -= alpha * (v_dw / (np.sqrt(s_dw) + epsilon))
            b -= alpha * (v_db / (np.sqrt(s_db) + epsilon))
        else: # Standard GD
            w -= alpha * gradient_w
            b -= alpha * gradient_b
        
        if not np.isfinite(w).all() or not np.isfinite(b):
            print("ğŸ›‘ Divergence detected! Stopping training.")
            final_cost = np.inf 
            cost_history.append(final_cost)
            break

        if i % 1000 == 0:
            cost = (1 / (2 * m)) * np.sum(error**2)
            cost_history.append(cost)
    
    final_cost = cost_history[-1] if 'final_cost' not in locals() else initial_cost
    print(f"âœ… Training complete. Final Cost: {final_cost}")
    
    results = {
        "w": w, "b": b, "x_mean": x_mean, "x_std": x_std,
        "initial_cost": initial_cost, "final_cost": final_cost, "cost_history": cost_history,
        "use_poly": use_poly, "x_train": x_train, "x_scaled": x_scaled,
        "y_train_scaled": y_train_scaled, "feature_names": feature_names,
        "hyperparameters": {'optimizer': optimizer, 'poly_features': use_poly, 'epochs': epochs, 'alpha': alpha}
    }
    return results

# --- 4. ØªØ¹Ø±ÙŠÙ Ø§Ù„ØµÙØ­Ø§Øª ÙƒÙˆØ¸Ø§Ø¦Ù ---

def page_lab(lang):
    st.title(TEXTS['title'][lang])
    st.text(TEXTS['intro'][lang])

    with st.container(border=True):
        st.subheader(TEXTS['training_settings_header'][lang])
        col1, col2, col3 = st.columns(3)
        with col1:
            optimizer_choice = st.selectbox(TEXTS['optimizer_label'][lang], options=["Adam (Ø§Ù„Ù…Ø·ÙˆØ±)", "GD (Ø§Ù„Ø¹Ø§Ø¯ÙŠ)"], help=TEXTS['optimizer_help'][lang], index=0)
        with col2:
            epochs_choice = st.selectbox(TEXTS['epochs_label'][lang], options=[10000, 20000, 30000, 50000], index=3, help=TEXTS['epochs_help'][lang])
        with col3:
            # --- [ ØªØ¹Ø¯ÙŠÙ„ ] --- Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø±Ø§Øª Ø£Ù„ÙØ§ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            alpha_options = [0.001, 0.005, 0.01, 0.1, 0.3, 1.0, 3.0]
            alpha_default_index = 2 # 0.01
            alpha_choice = st.selectbox(TEXTS['alpha_label'][lang], options=alpha_options, index=alpha_default_index, help=TEXTS['alpha_help'][lang])
        poly_choice = st.checkbox(TEXTS['poly_label'][lang], value=True, help=TEXTS['poly_help'][lang])

    with st.container(border=True):
        st.subheader(TEXTS['property_details_header'][lang])
        c1, c2 = st.columns(2)
        with c1:
            area = st.slider(TEXTS['area_label'][lang], 50, 1000, 150)
            rooms = st.slider(TEXTS['rooms_label'][lang], 1, 10, 4)
            floors = st.slider(TEXTS['floors_label'][lang], 1, 5, 2)
        with c2:
            finishing = st.slider(TEXTS['finishing_label'][lang], 1, 5, 4)
            property_age = st.slider(TEXTS['age_label'][lang], 0, 30, 5)
            neighborhood_name = st.selectbox(TEXTS['neighborhood_label'][lang], list(neighborhood_options.keys()))

    if st.button(TEXTS['button_text'][lang], type="primary", use_container_width=True):
        spinner_text = f"{TEXTS['spinner_text'][lang]} (Optimizer: {optimizer_choice}, Epochs: {epochs_choice}, Alpha: {alpha_choice})"
        with st.spinner(spinner_text):
            st.session_state.model_results = train_live_model(epochs_choice, alpha_choice, poly_choice, "Adam" if "Adam" in optimizer_choice else "GD")
        
        results = st.session_state.model_results
        
        if np.isinf(results['final_cost']):
            st.error(TEXTS['divergence_error'][lang], icon="ğŸš¨")
        else:
            st.header(TEXTS['results_header'][lang])
            res_col1, res_col2 = st.columns(2)
            with res_col1:
                neighborhood_value = neighborhood_options[neighborhood_name]
                user_features = np.array([area, rooms, floors, finishing, neighborhood_value, property_age])
                if results['use_poly']:
                    user_features = np.append(user_features, [user_features[0]**2, user_features[5]**2, user_features[3]**2])
                
                x_user_scaled = (user_features - results['x_mean']) / results['x_std']
                y_user_pred_scaled = np.dot(x_user_scaled, results['w']) + results['b']
                
                st.metric(label=f"{TEXTS['price_label'][lang]} - {neighborhood_name}", value=f"{y_user_pred_scaled:,.0f}K")

            with res_col2:
                rmse = np.sqrt(results['final_cost'])
                st.metric(label=TEXTS['rmse_label'][lang], value=f"Â± {rmse:,.0f}K", help=TEXTS['rmse_help'][lang])

            res_col3, res_col4 = st.columns(2)
            with res_col3:
                st.metric(label=TEXTS['initial_cost_label'][lang], value=f"{results['initial_cost']:,.2f}")
            with res_col4:
                st.metric(label=TEXTS['final_cost_label'][lang], value=f"{results['final_cost']:,.2f}", 
                          delta=f"{results['final_cost'] - results['initial_cost']:,.2f}", delta_color="inverse",
                          help=TEXTS['cost_help'][lang])
            
            st.info(TEXTS['tip_header'][lang], icon="ğŸ’¡")
            st.markdown(TEXTS['tip_text'][lang])

def page_analysis(lang):
    st.title(TEXTS['analysis_title'][lang])
    if 'model_results' not in st.session_state:
        st.warning(TEXTS['run_lab_first'][lang], icon="ğŸ‘ˆ")
        return

    results = st.session_state.model_results
    params = results['hyperparameters']
    
    with st.expander(TEXTS['summary_header'][lang], expanded=True):
        st.json({
            TEXTS['summary_optimizer'][lang]: params['optimizer'],
            TEXTS['summary_poly'][lang]: params['poly_features'],
            TEXTS['summary_epochs'][lang]: params['epochs'],
            TEXTS['summary_alpha'][lang]: params['alpha'],
            TEXTS['summary_final_cost'][lang]: f"{results['final_cost']:.2f}" if np.isfinite(results['final_cost']) else "Diverged"
        })

    st.subheader(TEXTS['charts_header'][lang])
    y_pred_scaled = np.dot(results['x_scaled'], results['w']) + results['b']
    residuals = results['y_train_scaled'] - y_pred_scaled
    plt.style.use('dark_background')
    matplotlib.rcParams.update({'font.size': 12, 'text.color': 'white', 'axes.labelcolor': 'white', 'xtick.color': 'white', 'ytick.color': 'white'})

    fig_conv, ax_conv = plt.subplots(figsize=(12, 6))
    fig_conv.patch.set_facecolor('#0E1117')
    ax_conv.set_facecolor('#0E1117')
    ax_conv.plot(np.arange(len(results['cost_history'])) * 1000, results['cost_history'], color='#FF4B4B', marker='o', markersize=3, linestyle='-')
    ax_conv.set_title(TEXTS['chart_convergence_title']['en'])
    ax_conv.set_xlabel(TEXTS['chart_convergence_xaxis']['en'])
    ax_conv.set_ylabel(TEXTS['chart_convergence_yaxis']['en'])
    ax_conv.grid(True, linestyle='--', alpha=0.3)
    st.pyplot(fig_conv)

    col1, col2 = st.columns(2)
    with col1:
        fig1, ax1 = plt.subplots(figsize=(8, 6))
        fig1.patch.set_facecolor('#0E1117')
        ax1.set_facecolor('#0E1117')
        ax1.scatter(results['y_train_scaled'], y_pred_scaled, alpha=0.7, color='#B57BFF', label='Predictions')
        ax1.plot([results['y_train_scaled'].min(), results['y_train_scaled'].max()], [results['y_train_scaled'].min(), results['y_train_scaled'].max()], 'r--', lw=2, label='Perfect Fit')
        ax1.set_title(TEXTS['chart_actual_vs_pred_title']['en'])
        ax1.set_xlabel(TEXTS['chart_actual_vs_pred_xaxis']['en'])
        ax1.set_ylabel(TEXTS['chart_actual_vs_pred_yaxis']['en'])
        ax1.grid(True, linestyle='--', alpha=0.3)
        st.pyplot(fig1)

    with col2:
        fig2, ax2 = plt.subplots(figsize=(8, 6))
        fig2.patch.set_facecolor('#0E1117')
        ax2.set_facecolor('#0E1117')
        ax2.scatter(y_pred_scaled, residuals, alpha=0.7, color='#00C49A')
        ax2.axhline(y=0, color='r', linestyle='--', lw=2)
        ax2.set_title(TEXTS['chart_residuals_title']['en'])
        ax2.set_xlabel(TEXTS['chart_residuals_xaxis']['en'])
        ax2.set_ylabel(TEXTS['chart_residuals_yaxis']['en'])
        ax2.grid(True, linestyle='--', alpha=0.3)
        st.pyplot(fig2)

    fig3, ax3 = plt.subplots(figsize=(10, 7))
    fig3.patch.set_facecolor('#0E1117')
    ax3.set_facecolor('#0E1117')
    weights = pd.Series(results['w'], index=results['feature_names'])
    weights.plot(kind='barh', ax=ax3, color='#FFC65C')
    ax3.set_title(TEXTS['chart_importance_title']['en'])
    st.pyplot(fig3)

    with st.expander(TEXTS['table_header'][lang]):
        df = pd.DataFrame({
            'Actual Price (K)': np.round(results['y_train_scaled'], 1),
            'Predicted Price (K)': np.round(y_pred_scaled, 1),
            'Difference (K)': np.round(residuals, 1)
        })
        st.dataframe(df)
        
    with st.expander(TEXTS['params_header'][lang]):
        st.write({"Weights (w)": results['w'].tolist(), "Bias (b)": results['b']})
        
    with st.expander(TEXTS['data_header'][lang]):
        st.dataframe(pd.DataFrame(x_train_data, columns=FEATURE_NAMES[:6]))

# --- 5. Ø§Ù„Ù…Ø´ØºÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ ---
lang_choice = st.sidebar.radio(TEXTS['lang_choice']['ar'], ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
lang = 'ar' if lang_choice == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else 'en'
page_options = [TEXTS['page_lab'][lang], TEXTS['page_analysis'][lang]]
page = st.sidebar.radio(TEXTS['page_choice'][lang], page_options, label_visibility="hidden")
if page == TEXTS['page_lab'][lang]:
    page_lab(lang)
elif page == TEXTS['page_analysis'][lang]:
    page_analysis(lang)
st.sidebar.divider()
st.sidebar.caption("ğŸ‘¨â€ğŸ’» Developed by: MTMA | ğŸ“§ mtma.1@hotmail.com | ğŸŒ iq.sa")